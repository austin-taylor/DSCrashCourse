{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DataFrame Worksheet - Building the Dataset\n",
    "##Step 1:  \n",
    "We have two lists of URLs.  The whitelist contains 400 URLs that are not malicious--specificially they are from Alexa's top 1 million websites, and another list of malicious URLs.  The first step is to read in both the whitelist and blacklists into sepearate DataFrames and take a random sample of these URLs.  The file names are ```url-whitelist.csv``` and ```url-blacklist.csv``` respectively. Next, add a column called ```isMalicious``` to both DataFrames.  Set this column to 1 for the blacklist and 0 for the whitelist.  Please drop any extraneous columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whitelist = pd.read_csv( '../Data/url-whitelist.csv', names=['rank', 'url'])\n",
    "whitelist = whitelist.drop( 'rank', axis=1)\n",
    "whitelist['isMalicious'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>isMalicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yahoo.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            url  isMalicious\n",
       "0    google.com            0\n",
       "1  facebook.com            0\n",
       "2   youtube.com            0\n",
       "3     baidu.com            0\n",
       "4     yahoo.com            0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitelist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist = pd.read_csv( '../Data/url-blacklist', names=['url','something'] )\n",
    "blacklist = blacklist.drop( 'something', axis=1)\n",
    "blacklist = blacklist.sample(400)\n",
    "blacklist['isMalicious'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 2:  Merging the data files:\n",
    "Now that you have these two data sets, merge them together and create a new dataframe called ```urlData```.  If you ran ```urlData.isMalicious.value_counts()``` you should get the following output.\n",
    "```python\n",
    "1    400\n",
    "0    400\n",
    "dtype: int64\n",
    "```\n",
    "You should have a file called ```domainData.xlsx``` which contains whois information about the hostnames. Merge this data with the ```urlData``` dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    400\n",
       "0    400\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlData.isMalicious.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = pd.read_excel( '../Data/domainData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>name_servers</th>\n",
       "      <th>registrar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nuteczki.com</td>\n",
       "      <td>2014-04-10</td>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>2015-04-03 00:00:00</td>\n",
       "      <td>{'ns1.castpol.pl', 'ns2.castpol.pl'}</td>\n",
       "      <td>KEY-SYSTEMS GMBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daftarcaramembuat.com</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>2015-05-14 00:00:00</td>\n",
       "      <td>{'ns1.idwebhost.id', 'ns2.idwebhost.id'}</td>\n",
       "      <td>CV. JOGJACAMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>price59.ru</td>\n",
       "      <td>2009-06-11</td>\n",
       "      <td>2016-06-11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>{'ns4.linode.com', 'ns2.linode.com', 'ns3.lino...</td>\n",
       "      <td>REGRU-RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bulinews.de</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2014-11-20 11:51:55</td>\n",
       "      <td>{'ns-de.1and1-dns.de', 'ns-de.1and1-dns.com', ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buildyourownclone.com</td>\n",
       "      <td>2004-11-04</td>\n",
       "      <td>2015-11-04</td>\n",
       "      <td>2014-02-05 00:00:00</td>\n",
       "      <td>{'yns2.yahoo.com', 'yns1.yahoo.com'}</td>\n",
       "      <td>MELBOURNE IT, LTD. D/B/A INTERNET NAMES WORLDWIDE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     url creation_date expiration_date        last_updated  \\\n",
       "0           nuteczki.com    2014-04-10      2016-04-10 2015-04-03 00:00:00   \n",
       "1  daftarcaramembuat.com    2015-01-31      2016-01-31 2015-05-14 00:00:00   \n",
       "2             price59.ru    2009-06-11      2016-06-11                 NaT   \n",
       "3            bulinews.de           NaT             NaT 2014-11-20 11:51:55   \n",
       "4  buildyourownclone.com    2004-11-04      2015-11-04 2014-02-05 00:00:00   \n",
       "\n",
       "                                        name_servers  \\\n",
       "0               {'ns1.castpol.pl', 'ns2.castpol.pl'}   \n",
       "1           {'ns1.idwebhost.id', 'ns2.idwebhost.id'}   \n",
       "2  {'ns4.linode.com', 'ns2.linode.com', 'ns3.lino...   \n",
       "3  {'ns-de.1and1-dns.de', 'ns-de.1and1-dns.com', ...   \n",
       "4               {'yns2.yahoo.com', 'yns1.yahoo.com'}   \n",
       "\n",
       "                                           registrar  \n",
       "0                                   KEY-SYSTEMS GMBH  \n",
       "1                                      CV. JOGJACAMP  \n",
       "2                                           REGRU-RU  \n",
       "3                                                NaN  \n",
       "4  MELBOURNE IT, LTD. D/B/A INTERNET NAMES WORLDWIDE  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 2a:  Retrieving Data From WHOIS (Optional Step)\n",
    "Our original idea was to have you retrieve the whois data from actual sources, however we couldn't find a free, reliable API for whois.  In any event, here is some code to do that if you want.\n",
    "\n",
    "```python\n",
    "def getUrlData( row ):\n",
    "    try:\n",
    "        data = pd.read_json( 'https://whois.apitruck.com/:' + row['url'] )\n",
    "        data = data.drop( 'error', axis=1 )\n",
    "        data = data.T\n",
    "        row['created'] = data['created'].iloc[0]\n",
    "        row['changed'] = data['changed'].iloc[0]\n",
    "        row['expires'] = data['expires'].iloc[0]\n",
    "    \n",
    "        row['dnssec'] = data['dnssec'].iloc[0]\n",
    "        return row\n",
    "    except:\n",
    "        print( \"Could not find: \" + row['url'] )\n",
    "        row['created'] = False\n",
    "        row['changed'] = False\n",
    "        row['expires'] = False\n",
    "        return row\n",
    "\n",
    "\n",
    "urlData = urlData.apply( getUrlData, axis=1, reduce=False )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step 3:  Convert the Dates\n",
    "Once you've done all that, convert all the date/time columns from strings to date/time indexes. HINT: You might want to use the ```pd.to_datetime()``` method for this.  HINT: Read the documentation for the ```coerce``` option.  Finally add a column called ```daysToExpire``` which is the difference between the creation date and the expiration date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Step 4:  Save your Data\n",
    "The last step is to save your dataset into a CSV file by using the ```<data>.to_csv()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
